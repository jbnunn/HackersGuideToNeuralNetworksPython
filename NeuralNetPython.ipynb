{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://karpathy.github.io/neuralnets/\n",
    "#\n",
    "# Via Hacker news: https://news.ycombinator.com/item?id=18840747\n",
    "\n",
    "# This eventually turned into Andrej Karpathy's class at \n",
    "# Stanford, CS231n. The class notes are here: \n",
    "# http://cs231n.github.io/\n",
    "#\n",
    "# A lot of the compute graph and backprop details in the hacker's \n",
    "# guide is covered in this specific class, starting near this time: \n",
    "# https://www.youtube.com/watch?v=i94OvYb6noo&t=207s\n",
    "\n",
    "# Note: I converted @karpathy's Javascript in the guide to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Real-valued Circuits\n",
    "\n",
    "## Base Case: Single Gate in the Circuit\n",
    "\n",
    "Lets first consider a single, simple circuit with one gate. Here’s an example:\n",
    "\n",
    "![Single Gate](./single.png)\n",
    "\n",
    "This circuit takes two inputs, `x` and `y`, and computes `x * y` with the `*` gate (there can be `*` gates, `+` gates, `max` gates, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: -6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's see the code for this gate in action:\n",
    "\n",
    "f(x,y)=xy\n",
    "\"\"\"\n",
    "def forward_multiply_gate(x, y):\n",
    "    return x * y\n",
    "output = forward_multiply_gate(-2, 3)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Goal\n",
    "\n",
    "The problem we are interested in studying looks as follows:\n",
    "\n",
    "We provide a given circuit some specific input values (e.g. `x = -2`, `y = 3`). The circuit computes an output value (e.g. `-6`).\n",
    "\n",
    "The core question then becomes: **How should one tweak the input(s) slightly to increase the output?**\n",
    "\n",
    "In this case, in what direction should we change `x,y` to get a number larger than `-6`?\n",
    "\n",
    "Note that, for example, `x = -1.99` and `y = 2.99` gives `x * y = -5.95`, which is higher than `-6.0`. Don’t get confused by this: `-5.95` is better (higher) than `-6.0`. It’s an improvement of `0.05`, even though the magnitude of `-5.95` (the distance from zero) happens to be lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: -5.950100000000001\n"
     ]
    }
   ],
   "source": [
    "## Let's see how adjusting X and Y affect the output\n",
    "output = forward_multiply_gate(-1.99, 2.99)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 1: Random Local Search\n",
    "\n",
    "A simple gate like this is trivial, you can easily adjust inputs to get a desired value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best X: -1.81, Best Y: 2.99, Total: -5.4119)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "x = -2\n",
    "y = 3\n",
    "\n",
    "# Try changing x,y randomly small amounds and keep track of what works\n",
    "tweak_amount = 0.01\n",
    "best_out = -float('inf') # infinity\n",
    "best_x = x\n",
    "best_y = y\n",
    "\n",
    "for k in range(0,100):\n",
    "    x_try = x + tweak_amount * (random.randint(0,10) * 2 - 1)\n",
    "    y_try = y + tweak_amount * (random.randint(0,10) * 2 - 1)\n",
    "    out = forward_multiply_gate(x_try, y_try)\n",
    "    \n",
    "    if out > best_out:\n",
    "        best_out = out\n",
    "        best_x = x_try\n",
    "        best_y = y_try\n",
    "\n",
    "# We should have something < -6        \n",
    "print(\"Best X: {}, Best Y: {}, Total: {})\".format(best_x, best_y, best_x * best_y))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we’re done, right? Not quite: This is a perfectly fine strategy \n",
    "for tiny problems with a few gates if you can afford the compute \n",
    "time, but it won’t do if we want to eventually consider huge \n",
    "circuits with millions of inputs. \n",
    "\n",
    "It turns out that we can do much better.\n",
    "\n",
    "## Strategy 2: Numerical Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: -5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here's how to imagine this. Imagine pulling on the output value to make it \n",
    "larger. It might exert a force on X that makes the output higher, than -6 e.g.\n",
    "\"\"\"\n",
    "output = forward_multiply_gate(x + 1, y) # Let's \"pull\" on x\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of the \"pulling\" of an input value in a positive or negative direction. The forces affecting the values are known as the **derivative** of the output value with respect to the inputs (`x` and `y`). \n",
    "\n",
    "**The derivative can be thought of as a force on each input as we pull on the output to become higher.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X plus H: -1.9999\n",
      "Output with tweaked X: -5.9997\n",
      "x': 3.00000000000189\n",
      "\n",
      "Y plus H: 3.0001\n",
      "Output with tweaked Y: -6.0002\n",
      "y': -2.0000000000042206\n",
      "\n",
      "Before gradient: -6\n",
      "Output after gradient: -6.000000000016442\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We've just learned about the \"derivative\" of the output value with respect to \n",
    "its inputs (x and y).\n",
    " \n",
    "It's a very simple procedure. Instead of pulling on the circuit’s output, we’ll \n",
    "iterate over every input one by one, increase it very slightly and look at what \n",
    "happens to the output value. The amount the output changes in response is the \n",
    "derivative.\n",
    "\n",
    "Here's the formula for the derivative with respect to x:\n",
    "\n",
    "∂f(x, y)     f(x + h, y) - f(x, y)\n",
    "--------  =  -------------------\n",
    "∂x                     h\n",
    "\n",
    "\n",
    "A \"derivative\" is with respect to a single input. The gradient is a collection \n",
    "of ALL the derivatives. (It's represented as a concatendated list, a vector--not shown.)\n",
    "\n",
    "\"\"\"\n",
    "x = -2\n",
    "y = 3\n",
    "h = 0.0001\n",
    "output = forward_multiply_gate(x, y)\n",
    "\n",
    "# Compute the derivative with respect to x\n",
    "# (...What happens when we turn the knob x to x + h)\n",
    "xph = x + h\n",
    "print(\"X plus H:\", xph) # -1.9999\n",
    "output2 = forward_multiply_gate(xph, y)\n",
    "print(\"Output with tweaked X:\", output2) # -5.9997\n",
    "derivative_x = (output2 - output) / h\n",
    "print(\"x':\", derivative_x)\n",
    "print()\n",
    "\n",
    "# Compute the derivative with respect to y\n",
    "# (...What happens when we turn the knob y to y + h)\n",
    "yph = y + h\n",
    "print(\"Y plus H:\", yph) # 3.0001\n",
    "output3 = forward_multiply_gate(x, yph)\n",
    "print(\"Output with tweaked Y:\", output3) # -6.0002\n",
    "derivative_y = (output3 - output) / h\n",
    "print(\"y':\", derivative_y)\n",
    "print()\n",
    "\n",
    "before_tweak = forward_multiply_gate(x, y)\n",
    "print(\"Before gradient:\", before_tweak)\n",
    "output = forward_multiply_gate(derivative_x, derivative_y);\n",
    "print(\"Output after gradient:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we allow the inputs respond to the tub gy following the gradient a tiny amount (i.e. we just add the derivative on top of every input), we can see the value increases, as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: -6\n",
      "x: -1.969999999999981\n",
      "y: 2.979999999999958\n",
      "Final output: -5.87059999999986\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.01\n",
    "x = -2\n",
    "y = 3\n",
    "\n",
    "output = forward_multiply_gate(x, y) # Before, -6\n",
    "print(\"Output:\",output)\n",
    "\n",
    "x = x + (step_size * derivative_x) # x becomes -1.97\n",
    "print(\"x:\", x)\n",
    "\n",
    "y = y + (step_size * derivative_y) # y becomes 2.98\n",
    "print(\"y:\", y)\n",
    "\n",
    "output_new = forward_multiply_gate(x, y) # -5.87, which achieves the goal of being greater than the original -6\n",
    "print(\"Final output:\", output_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 3: Analytic Gradient\n",
    "\n",
    "In the previous section we evaluated the gradient by probing the \n",
    "circuit’s output value, independently for every input. This procedure \n",
    "gives you what we call a numerical gradient. This approach, however, \n",
    "is still expensive because we need to compute the circuit’s output as \n",
    "we tweak every input value independently a small amount. So the \n",
    "complexity of evaluating the gradient is linear in number of inputs. \n",
    "But in practice we will have hundreds, thousands or (for neural networks) \n",
    "even tens to hundreds of millions of inputs, and the circuits aren’t \n",
    "just one multiply gate but huge expressions that can be expensive to \n",
    "compute. We need something better.\n",
    "\n",
    "Luckily, there is an easier and much faster way to compute the gradient: \n",
    "we can use calculus to derive a direct expression for it that will be as\n",
    "simple to evaluate as the circuit’s output value. We call this an analytic\n",
    "gradient and there will be no need for tweaking anything.\n",
    "\n",
    "**The analytic derivative requires no tweaking of the inputs. It can be derived using mathematics (calculus).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.8706\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For our function, f(x, y) = (x * y), the derivative of x is y, \n",
    "and the derivative of y is x:\n",
    "\"\"\"\n",
    "\n",
    "x = -2\n",
    "y = 3\n",
    "output = forward_multiply_gate(x, y) # Before: -6\n",
    "\n",
    "x_gradient = y\n",
    "y_gradient = x\n",
    "\n",
    "step_size = 0.01\n",
    "x += step_size * x_gradient # -1.97\n",
    "y += step_size * y_gradient # 2.98\n",
    "\n",
    "output_new = forward_multiply_gate(x,y)\n",
    "print(output_new) # -5.87, which achieves the goal of being greater than the original -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Case: Circuits with Multiple Gates\n",
    "\n",
    "“The analytic gradient was trivial to derive for your super-simple expression. This is useless. What do I do when the expressions are much larger? Don’t the equations get huge and complex very fast?”. Good question. Yes the expressions get much more complex. No, this doesn’t make it much harder. As we will see, every gate will be hanging out by itself, completely unaware of any details of the huge and complex circuit that it could be part of. It will only worry about its inputs and it will compute its local derivatives as seen in the previous section, except now there will be a single extra multiplication it will have to do.\n",
    "\n",
    "![Recursive](./recursive_case.png)\n",
    "\n",
    "The expression we are computing now is f(x,y,z) = (x+y)z. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:  -6\n"
     ]
    }
   ],
   "source": [
    "# The expression we are now computing is f(x, y, z) = (x + y)z\n",
    "\n",
    "def forward_multiply_gate(a, b): # Redfining inputs as a, b to indicate they are local\n",
    "    return a * b                 # variables and not to be confused with x, y, z later\n",
    "\n",
    "def forward_add_gate(a, b):\n",
    "    return a + b\n",
    "\n",
    "def forward_circuit(x, y, z):\n",
    "    q = forward_add_gate(x, y)\n",
    "    f = forward_multiply_gate(q, z)\n",
    "    return f\n",
    "\n",
    "x = -2\n",
    "y = 5\n",
    "z = -4\n",
    "\n",
    "f = forward_circuit(x, y, z) \n",
    "print(\"f: \", output) # output is -12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
